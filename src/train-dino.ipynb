{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":93787,"databundleVersionId":11165379,"sourceType":"competition"}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!git clone https://github.com/lucasmurray97/dlmi-project.git","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T09:31:45.693659Z","iopub.execute_input":"2025-04-01T09:31:45.693963Z","iopub.status.idle":"2025-04-01T09:31:46.840478Z","shell.execute_reply.started":"2025-04-01T09:31:45.693934Z","shell.execute_reply":"2025-04-01T09:31:46.839456Z"}},"outputs":[{"name":"stdout","text":"Cloning into 'dlmi-project'...\nremote: Enumerating objects: 65, done.\u001b[K\nremote: Counting objects: 100% (65/65), done.\u001b[K\nremote: Compressing objects: 100% (46/46), done.\u001b[K\nremote: Total 65 (delta 31), reused 46 (delta 15), pack-reused 0 (from 0)\u001b[K\nReceiving objects: 100% (65/65), 2.15 MiB | 13.77 MiB/s, done.\nResolving deltas: 100% (31/31), done.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"cd dlmi-project","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T09:31:53.441650Z","iopub.execute_input":"2025-04-01T09:31:53.441961Z","iopub.status.idle":"2025-04-01T09:31:53.451501Z","shell.execute_reply.started":"2025-04-01T09:31:53.441934Z","shell.execute_reply":"2025-04-01T09:31:53.450851Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working/dlmi-project\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"cp -r /kaggle/input/mva-dlmi-2025-histopathology-ood-classification/* /kaggle/working/dlmi-project/data/","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T09:31:54.806629Z","iopub.execute_input":"2025-04-01T09:31:54.806919Z","iopub.status.idle":"2025-04-01T09:35:00.802629Z","shell.execute_reply.started":"2025-04-01T09:31:54.806895Z","shell.execute_reply":"2025-04-01T09:35:00.801561Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"!pip install umap-learn","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T09:36:30.949044Z","iopub.execute_input":"2025-04-01T09:36:30.949443Z","iopub.status.idle":"2025-04-01T09:36:36.873237Z","shell.execute_reply.started":"2025-04-01T09:36:30.949410Z","shell.execute_reply":"2025-04-01T09:36:36.872020Z"}},"outputs":[{"name":"stdout","text":"Collecting umap-learn\n  Downloading umap_learn-0.5.7-py3-none-any.whl.metadata (21 kB)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from umap-learn) (1.26.4)\nRequirement already satisfied: scipy>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from umap-learn) (1.13.1)\nRequirement already satisfied: scikit-learn>=0.22 in /usr/local/lib/python3.10/dist-packages (from umap-learn) (1.2.2)\nRequirement already satisfied: numba>=0.51.2 in /usr/local/lib/python3.10/dist-packages (from umap-learn) (0.60.0)\nCollecting pynndescent>=0.5 (from umap-learn)\n  Downloading pynndescent-0.5.13-py3-none-any.whl.metadata (6.8 kB)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from umap-learn) (4.67.1)\nRequirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.2->umap-learn) (0.43.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->umap-learn) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->umap-learn) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->umap-learn) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->umap-learn) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->umap-learn) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->umap-learn) (2.4.1)\nRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.10/dist-packages (from pynndescent>=0.5->umap-learn) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22->umap-learn) (3.5.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->umap-learn) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->umap-learn) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->umap-learn) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->umap-learn) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->umap-learn) (2024.2.0)\nDownloading umap_learn-0.5.7-py3-none-any.whl (88 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.8/88.8 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pynndescent-0.5.13-py3-none-any.whl (56 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.9/56.9 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: pynndescent, umap-learn\nSuccessfully installed pynndescent-0.5.13 umap-learn-0.5.7\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"!nvidia-smi","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T09:36:40.599944Z","iopub.execute_input":"2025-04-01T09:36:40.600451Z","iopub.status.idle":"2025-04-01T09:36:40.824892Z","shell.execute_reply.started":"2025-04-01T09:36:40.600418Z","shell.execute_reply":"2025-04-01T09:36:40.824008Z"}},"outputs":[{"name":"stdout","text":"Tue Apr  1 09:36:40 2025       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n| N/A   33C    P8              9W /   70W |       1MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n|   1  Tesla T4                       Off |   00000000:00:05.0 Off |                    0 |\n| N/A   37C    P8              9W /   70W |       1MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n                                                                                         \n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n|  No running processes found                                                             |\n+-----------------------------------------------------------------------------------------+\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"!python src/dino_mod/main_dino.py --data_path ./data --output_dir ./checkpoints --epochs 12 --warmup_epochs 1 --num_workers 4 --batch_size_per_gpu 64 --saveckp_freq 1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T09:37:01.208864Z","iopub.execute_input":"2025-04-01T09:37:01.209227Z","iopub.status.idle":"2025-04-01T09:38:31.951763Z","shell.execute_reply.started":"2025-04-01T09:37:01.209194Z","shell.execute_reply":"2025-04-01T09:38:31.950927Z"}},"outputs":[{"name":"stdout","text":"Downloading: \"https://github.com/facebookresearch/xcit/zipball/main\" to /root/.cache/torch/hub/main.zip\n/usr/local/lib/python3.10/dist-packages/timm/models/registry.py:4: FutureWarning: Importing from timm.models.registry is deprecated, please import via timm.models\n  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.models\", FutureWarning)\n/usr/local/lib/python3.10/dist-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\nWill run the code on one GPU.\n| distributed init (rank 0): env://\n[rank0]:[W401 09:37:15.756915311 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.\ngit:\n  sha: 7ab59db726e4f138068f73235d103235b16c4dc8, status: clean, branch: main\n\narch: vit_small\nbatch_size_per_gpu: 64\nclip_grad: 3.0\ndata_path: ./data\ndist_url: env://\ndrop_path_rate: 0.1\nepochs: 12\nfreeze_last_layer: 1\nglobal_crops_scale: (0.4, 1.0)\ngpu: 0\nlocal_crops_number: 8\nlocal_crops_scale: (0.05, 0.4)\nlocal_rank: 0\nlr: 0.0005\nmin_lr: 1e-06\nmomentum_teacher: 0.996\nnorm_last_layer: True\nnum_workers: 4\noptimizer: adamw\nout_dim: 65536\noutput_dir: ./checkpoints\npatch_size: 16\nrank: 0\nsaveckp_freq: 1\nseed: 0\nteacher_temp: 0.04\nuse_bn_in_head: False\nuse_fp16: True\nwarmup_epochs: 1\nwarmup_teacher_temp: 0.04\nwarmup_teacher_temp_epochs: 0\nweight_decay: 0.04\nweight_decay_end: 0.4\nworld_size: 1\nData loaded: there are 219958 images.\n/usr/local/lib/python3.10/dist-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n  WeightNorm.apply(module, name, dim)\nStudent and Teacher are built: they are both vit_small network.\n/kaggle/working/dlmi-project/src/dino_mod/main_dino.py:243: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  fp16_scaler = torch.cuda.amp.GradScaler()\nLoss, optimizer and schedulers ready.\nStarting DINO training !\n/kaggle/working/dlmi-project/src/dino_mod/main_dino.py:328: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(fp16_scaler is not None):\nEpoch: [0/12]  [   0/3436]  eta: 10:17:10  loss: 10.683867 (10.683867)  lr: 0.000000 (0.000000)  wd: 0.040000 (0.040000)  time: 10.777317  data: 5.447418  max mem: 11170\nEpoch: [0/12]  [  10/3436]  eta: 1:46:18  loss: 10.890621 (10.876053)  lr: 0.000000 (0.000000)  wd: 0.040000 (0.040000)  time: 1.861741  data: 0.495487  max mem: 11500\nEpoch: [0/12]  [  20/3436]  eta: 1:22:08  loss: 10.988006 (10.959419)  lr: 0.000000 (0.000000)  wd: 0.040000 (0.040000)  time: 0.976171  data: 0.000454  max mem: 11500\nEpoch: [0/12]  [  30/3436]  eta: 1:14:54  loss: 11.081146 (11.008386)  lr: 0.000001 (0.000001)  wd: 0.040000 (0.040000)  time: 1.021296  data: 0.031587  max mem: 11500\nEpoch: [0/12]  [  40/3436]  eta: 1:11:55  loss: 11.110336 (11.035086)  lr: 0.000001 (0.000001)  wd: 0.040000 (0.040000)  time: 1.090229  data: 0.081632  max mem: 11500\n^C\n[rank0]: Traceback (most recent call last):\n[rank0]:   File \"/kaggle/working/dlmi-project/src/dino_mod/main_dino.py\", line 484, in <module>\n[rank0]:     train_dino(args)\n[rank0]:   File \"/kaggle/working/dlmi-project/src/dino_mod/main_dino.py\", line 281, in train_dino\n[rank0]:     train_stats = train_one_epoch(student, teacher, teacher_without_ddp, dino_loss,\n[rank0]:   File \"/kaggle/working/dlmi-project/src/dino_mod/main_dino.py\", line 317, in train_one_epoch\n[rank0]:     for it, (images, _) in enumerate(metric_logger.log_every(data_loader, 10, header)):\n[rank0]:   File \"/kaggle/working/dlmi-project/src/dino_mod/utils.py\", line 382, in log_every\n[rank0]:     for obj in iterable:\n[rank0]:   File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 701, in __next__\n[rank0]:     data = self._next_data()\n[rank0]:   File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1448, in _next_data\n[rank0]:     idx, data = self._get_data()\n[rank0]:   File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1402, in _get_data\n[rank0]:     success, data = self._try_get_data()\n[rank0]:   File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1243, in _try_get_data\n[rank0]:     data = self._data_queue.get(timeout=timeout)\n[rank0]:   File \"/usr/lib/python3.10/queue.py\", line 180, in get\n[rank0]:     self.not_empty.wait(remaining)\n[rank0]:   File \"/usr/lib/python3.10/threading.py\", line 324, in wait\n[rank0]:     gotit = waiter.acquire(True, timeout)\n[rank0]: KeyboardInterrupt\n","output_type":"stream"}],"execution_count":8}]}