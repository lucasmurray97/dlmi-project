# Histopathology Out-of-Distribution (OOD) Classification

### MVA Project DLMI 2025 â€” Group 37  
**Authors:** Lucas Murray-Hidalgo, Antoine Sicard  
**Emails:** lucasmurrayh@gmail.com, antoine.sicard96@gmail.com

## ğŸ§  Project Overview

This project addresses the challenge of classifying histological images as cancerous or non-cancerous across different medical centers. Domain shift caused by heterogeneous data sources often hinders model generalization. To tackle this, we explore domain adaptation techniques with a strong emphasis on **adversarial learning** and **self-supervised pretraining** using **DINOv2 (ViT-S/8)**.

---

## ğŸ” Motivation

Deep learning models can achieve remarkable results in cancer detection but struggle to generalize when trained on data from a single source. The project aims to:
- Learn **domain-invariant representations**.
- Mitigate **center-specific artifacts**.
- Improve **generalization to unseen data** through self-supervised learning and domain adversarial strategies.

---

## ğŸ§± Methodology

### 1. **Self-Supervised Pretraining**
- **Backbone:** DINOv2 (ViT-S/8), pretrained on ImageNet.
- **Augmentation:** Standard DINO-style augmentations.
- **Domain Discriminator:** MLP + Gradient Reversal Layer to discourage center-specific features.
- **Loss Function:**
  ```
  L_total = L_DINO + Î±(t) * L_adv
  ```
  where `Î±(t)` increases over time using a sigmoid schedule.

### 2. **Supervised Fine-Tuning**
- **Classifier Head:** MLP on top of the DINO backbone.
- **Two strategies tested:**
  - Frozen backbone
  - Partial unfreezing of deeper layers

---

## ğŸ§ª Experiments

Three pretraining setups were tested:
1. **Strong Adversarial**
2. **Weak Adversarial**
3. **No Adversarial (Baseline)**

We experimented with varying classifier architectures (1â€“4 layers, 128â€“256 dimensions) and different backbone freezing strategies.

**Key Takeaways:**
- Adversarial pretraining significantly improved generalization (â†‘ accuracy from 0.78 to >0.90).
- No performance gain from deeper classifier heads.
- Partial unfreezing decreased performanceâ€”suggesting overfitting on small labeled datasets.

---

## ğŸ“Š Results

| Strategy              | Validation Accuracy | Test Accuracy |
|-----------------------|---------------------|----------------|
| Strong Adversarial    | 0.90                | **0.904**      |
| Weak Adversarial      | 0.86                | **0.909**      |
| No Adversarial (Base) | 0.93                | 0.78           |

Note: Test results from Kaggle submissions. Due to limited submission quota, not all configurations were tested.

---

## ğŸ› ï¸ Architecture Summary

- **Feature Extractor:** DINOv2 ViT-S
- **Classification Head:** MLP (binary classifier)
- **Domain Discriminator:** MLP (5-class center classifier)
- **Gradient Reversal Layer** to enable adversarial training

---

## ğŸ“‚ Repository Structure (Suggested)

```
.
â”œâ”€â”€ data/                       # Medical images
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ dino_pretrain.py       # DINO with adversarial component
â”‚   â”œâ”€â”€ classifier.py          # Classification head
â”‚   â””â”€â”€ dann_baseline.py       # DANN implementation (optional)
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ training.py
â”‚   â”œâ”€â”€ evaluation.py
â”‚   â””â”€â”€ scheduler.py           # Custom alpha(t) scheduler
â”œâ”€â”€ results/
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
```

---

## ğŸ“š References

- Ganin & Lempitsky (2015). *Unsupervised Domain Adaptation by Backpropagation*.
- Oquab et al. (2024). *DINOv2: Learning Robust Visual Features Without Supervision*.
- Esteva et al. (2017). *Dermatologist-level classification of skin cancer*.

---

## ğŸ“Œ License

This project is licensed under the [CC BY 4.0 License](https://creativecommons.org/licenses/by/4.0/).
